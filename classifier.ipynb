{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import *\n",
    "from sklearn.dummy import *\n",
    "from sklearn.ensemble import *\n",
    "from sklearn.neighbors import *\n",
    "from sklearn.tree import *\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.calibration import *\n",
    "from sklearn.linear_model import *\n",
    "from sklearn.multiclass import *\n",
    "from sklearn.svm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loading the sms dataset into a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/sms-spam-collection-dataset/spam.csv', encoding=\"latin-1\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "remove column 2, 3 and 4 as they have no useful information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SMS</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 SMS  label\n",
       "0  Go until jurong point, crazy.. Available only ...      0\n",
       "1                      Ok lar... Joking wif u oni...      0\n",
       "2  Free entry in 2 a wkly comp to win FA Cup fina...      1\n",
       "3  U dun say so early hor... U c already then say...      0\n",
       "4  Nah I don't think he goes to usf, he lives aro...      0"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], axis=1, inplace=True)\n",
    "df['SMS'] = df['v2']\n",
    "df['label'] = df['v1'].map({'ham': 0, 'spam': 1})\n",
    "df.drop(['v1', 'v2'], axis=1, inplace=True)\n",
    "train_data = df[:4400]\n",
    "test_data = df[4400:]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform(classifiers, vectorizers, train_data, test_data):\n",
    "    max_score = 0\n",
    "    max_name = 0\n",
    "    for classifier in classifiers:\n",
    "        for vectorizer in vectorizers:\n",
    "        \n",
    "            # train\n",
    "            vectorize_text = vectorizer.fit_transform(train_data.SMS)\n",
    "            classifier.fit(vectorize_text, train_data.label)\n",
    "\n",
    "            # score\n",
    "            vectorize_text = vectorizer.transform(test_data.SMS)\n",
    "            score = classifier.score(vectorize_text, test_data.label)\n",
    "            name = classifier.__class__.__name__ + ' with ' + vectorizer.__class__.__name__ \n",
    "            print(name, score)\n",
    "        if score > max_score:\n",
    "            max_score = score\n",
    "            max_name = name\n",
    "    print ('===========================================')\n",
    "    print ('===========================================')\n",
    "    print (max_name, max_score)\n",
    "    print ('===========================================')\n",
    "    print ('===========================================')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list of various classifiers we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifiers = [\n",
    "        BernoulliNB(),\n",
    "        RandomForestClassifier(n_estimators=100, n_jobs=-1),\n",
    "        AdaBoostClassifier(),\n",
    "        BaggingClassifier(),\n",
    "        ExtraTreesClassifier(),\n",
    "        GradientBoostingClassifier(),\n",
    "        DecisionTreeClassifier(),\n",
    "        CalibratedClassifierCV(),\n",
    "        DummyClassifier(),\n",
    "        PassiveAggressiveClassifier(),\n",
    "        RidgeClassifier(),\n",
    "        RidgeClassifierCV(),\n",
    "        SGDClassifier(),\n",
    "        OneVsRestClassifier(SVC(kernel='linear')),\n",
    "        OneVsRestClassifier(LogisticRegression()),\n",
    "        KNeighborsClassifier()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list of various vectorizers we are going to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizers = [\n",
    "        CountVectorizer(),\n",
    "        TfidfVectorizer(),\n",
    "        HashingVectorizer()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "perform classification and save results to a new dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BernoulliNB with CountVectorizer 0.9778156996587031\n",
      "BernoulliNB with TfidfVectorizer 0.9778156996587031\n",
      "BernoulliNB with HashingVectorizer 0.8728668941979523\n",
      "RandomForestClassifier with CountVectorizer 0.976962457337884\n",
      "RandomForestClassifier with TfidfVectorizer 0.9761092150170648\n",
      "RandomForestClassifier with HashingVectorizer 0.9658703071672355\n",
      "AdaBoostClassifier with CountVectorizer 0.9718430034129693\n",
      "AdaBoostClassifier with TfidfVectorizer 0.9692832764505119\n",
      "AdaBoostClassifier with HashingVectorizer 0.9735494880546075\n",
      "BaggingClassifier with CountVectorizer 0.9684300341296929\n",
      "BaggingClassifier with TfidfVectorizer 0.9658703071672355\n",
      "BaggingClassifier with HashingVectorizer 0.9701365187713311\n",
      "ExtraTreesClassifier with CountVectorizer 0.9726962457337884\n",
      "ExtraTreesClassifier with TfidfVectorizer 0.9778156996587031\n",
      "ExtraTreesClassifier with HashingVectorizer 0.9650170648464164\n",
      "GradientBoostingClassifier with CountVectorizer 0.9709897610921502\n",
      "GradientBoostingClassifier with TfidfVectorizer 0.9667235494880546\n",
      "GradientBoostingClassifier with HashingVectorizer 0.9726962457337884\n",
      "DecisionTreeClassifier with CountVectorizer 0.9641638225255973\n",
      "DecisionTreeClassifier with TfidfVectorizer 0.96160409556314\n",
      "DecisionTreeClassifier with HashingVectorizer 0.9607508532423208\n",
      "CalibratedClassifierCV with CountVectorizer 0.9872013651877133\n",
      "CalibratedClassifierCV with TfidfVectorizer 0.985494880546075\n",
      "CalibratedClassifierCV with HashingVectorizer 0.9820819112627986\n",
      "DummyClassifier with CountVectorizer 0.7687713310580204\n",
      "DummyClassifier with TfidfVectorizer 0.773037542662116\n",
      "DummyClassifier with HashingVectorizer 0.7738907849829352\n",
      "PassiveAggressiveClassifier with CountVectorizer 0.985494880546075\n",
      "PassiveAggressiveClassifier with TfidfVectorizer 0.984641638225256\n",
      "PassiveAggressiveClassifier with HashingVectorizer 0.9829351535836177\n",
      "RidgeClassifier with CountVectorizer 0.9812286689419796\n",
      "RidgeClassifier with TfidfVectorizer 0.9829351535836177\n",
      "RidgeClassifier with HashingVectorizer 0.9820819112627986\n",
      "RidgeClassifierCV with CountVectorizer 0.9829351535836177\n",
      "RidgeClassifierCV with TfidfVectorizer 0.9837883959044369\n",
      "RidgeClassifierCV with HashingVectorizer 0.9803754266211604\n",
      "SGDClassifier with CountVectorizer 0.9812286689419796\n",
      "SGDClassifier with TfidfVectorizer 0.9872013651877133\n",
      "SGDClassifier with HashingVectorizer 0.9820819112627986\n",
      "OneVsRestClassifier with CountVectorizer 0.9863481228668942\n",
      "OneVsRestClassifier with TfidfVectorizer 0.9880546075085325\n",
      "OneVsRestClassifier with HashingVectorizer 0.9829351535836177\n",
      "OneVsRestClassifier with CountVectorizer 0.9837883959044369\n",
      "OneVsRestClassifier with TfidfVectorizer 0.9752559726962458\n",
      "OneVsRestClassifier with HashingVectorizer 0.9692832764505119\n",
      "KNeighborsClassifier with CountVectorizer 0.924061433447099\n",
      "KNeighborsClassifier with TfidfVectorizer 0.962457337883959\n",
      "KNeighborsClassifier with HashingVectorizer 0.9607508532423208\n",
      "===========================================\n",
      "===========================================\n",
      "PassiveAggressiveClassifier with HashingVectorizer 0.9829351535836177\n",
      "===========================================\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "perform(\n",
    "    classifiers,\n",
    "    vectorizers,\n",
    "    train_data,\n",
    "    test_data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape='ovr', degree=3, gamma='auto_deprecated',\n",
       "  kernel='linear', max_iter=-1, probability=True, random_state=None,\n",
       "  shrinking=True, tol=0.001, verbose=False),\n",
       "          n_jobs=None)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train the classifier with best accuracy\n",
    "Classifier = OneVsRestClassifier(SVC(kernel='linear', probability=True))\n",
    "Vectorizer = TfidfVectorizer()\n",
    "vectorize_text = Vectorizer.fit_transform(train_data.SMS)\n",
    "Classifier.fit(vectorize_text, train_data.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMS = ' won a 1 week FREE membership in our $100,000 Prize Jackpot! Txt the word: C'\n",
    "vectorize_message = Vectorizer.transform([SMS])\n",
    "predict = Classifier.predict(vectorize_message)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spam\n"
     ]
    }
   ],
   "source": [
    "if predict == 0:\n",
    "    print ('ham')\n",
    "else:\n",
    "    print ('spam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
